{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "feda4d37-3b38-4fef-a92d-a2bf143be0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import random\n",
    "import requests\n",
    "from math import sqrt\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "506ae866-0720-4263-944e-c93d02710b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image  \\\n",
       "0  /1000268201_693b08cb0e.jpg   \n",
       "1  /1000268201_693b08cb0e.jpg   \n",
       "2  /1000268201_693b08cb0e.jpg   \n",
       "3  /1000268201_693b08cb0e.jpg   \n",
       "4  /1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0  A child in a pink dress is climbing up a set o...  \n",
       "1              A girl going into a wooden building .  \n",
       "2   A little girl climbing into a wooden playhouse .  \n",
       "3  A little girl climbing the stairs to her playh...  \n",
       "4  A little girl in a pink dress going into a woo...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = pd.read_csv(r\"C:\\Users\\KANISHK SINGH\\Desktop\\Vintern\\content\\data\\captions.txt\")\n",
    "captions['image'] = captions['image'].apply(\n",
    "    lambda x: f'/{x}')\n",
    "captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e51037a-a471-4c2d-843d-fb008c80193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    text = '[start] ' + text + ' [end]'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ae640ec-b559-49f6-b704-d662fcbeeeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>[start] a child in a pink dress is climbing up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>[start] a girl going into a wooden building [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>[start] a little girl climbing into a wooden p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>[start] a little girl climbing the stairs to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>[start] a little girl in a pink dress going in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image  \\\n",
       "0  /1000268201_693b08cb0e.jpg   \n",
       "1  /1000268201_693b08cb0e.jpg   \n",
       "2  /1000268201_693b08cb0e.jpg   \n",
       "3  /1000268201_693b08cb0e.jpg   \n",
       "4  /1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0  [start] a child in a pink dress is climbing up...  \n",
       "1  [start] a girl going into a wooden building [end]  \n",
       "2  [start] a little girl climbing into a wooden p...  \n",
       "3  [start] a little girl climbing the stairs to h...  \n",
       "4  [start] a little girl in a pink dress going in...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions['caption'] = captions['caption'].apply(preprocess)\n",
    "captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b69171d-eb1f-4f6d-a3cf-e35376e1bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] monster truck rides through dirt field [end]\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/508432819_3d055f395d.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(random_row\u001b[38;5;241m.\u001b[39mcaption)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m----> 4\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_row\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m im\n",
      "File \u001b[1;32mC:\\miniconda\\envs\\py\\lib\\site-packages\\PIL\\Image.py:3243\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3240\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3243\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3244\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/508432819_3d055f395d.jpg'"
     ]
    }
   ],
   "source": [
    "random_row = captions.sample(1).iloc[0]\n",
    "print(random_row.caption)\n",
    "print()\n",
    "im = Image.open(random_row.image)\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff2c1a52-73ba-4933-984a-25189ddedf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "VOCABULARY_SIZE = 10000\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "EMBEDDING_DIM = 512\n",
    "UNITS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d163318-b2ab-43b7-a86e-c233663b96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCABULARY_SIZE,\n",
    "    standardize=None,\n",
    "    output_sequence_length=MAX_LENGTH)\n",
    "\n",
    "tokenizer.adapt(captions['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eba6221c-9164-43c1-bd83-75e8802e6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tf.keras.layers.StringLookup(\n",
    "    mask_token=\"\",\n",
    "    vocabulary=tokenizer.get_vocabulary())\n",
    "\n",
    "idx2word = tf.keras.layers.StringLookup(\n",
    "    mask_token=\"\",\n",
    "    vocabulary=tokenizer.get_vocabulary(),\n",
    "    invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4ba966b-7a2d-4eb3-b0d2-ff7f9349662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_cap_vector = collections.defaultdict(list)\n",
    "for img, cap in zip(captions['image'], captions['caption']):\n",
    "    img_to_cap_vector[img].append(cap)\n",
    "\n",
    "img_keys = list(img_to_cap_vector.keys())\n",
    "random.shuffle(img_keys)\n",
    "\n",
    "slice_index = int(len(img_keys)*0.8)\n",
    "img_name_train_keys, img_name_val_keys = (img_keys[:slice_index], \n",
    "                                          img_keys[slice_index:])\n",
    "\n",
    "train_imgs = []\n",
    "train_captions = []\n",
    "for imgt in img_name_train_keys:\n",
    "    capt_len = len(img_to_cap_vector[imgt])\n",
    "    train_imgs.extend([imgt] * capt_len)\n",
    "    train_captions.extend(img_to_cap_vector[imgt])\n",
    "\n",
    "val_imgs = []\n",
    "val_captions = []\n",
    "for imgv in img_name_val_keys:\n",
    "    capv_len = len(img_to_cap_vector[imgv])\n",
    "    val_imgs.extend([imgv] * capv_len)\n",
    "    val_captions.extend(img_to_cap_vector[imgv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "306ce101-a900-48c1-aa68-ab24a5562c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32360, 32360, 8095, 8095)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_imgs), len(train_captions), len(val_imgs), len(val_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22b5ec80-0439-436f-9561-f58e43058b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, caption):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.keras.layers.Resizing(299, 299)(img)\n",
    "    img = img / 255.\n",
    "    caption = tokenizer(caption)\n",
    "    return img, caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98bbcca8-f039-403e-ace3-11f7f50f7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_imgs, train_captions))\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    load_data, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (val_imgs, val_captions))\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    load_data, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19f16c4a-3093-42bc-b50d-beb30cdf8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.2),\n",
    "        tf.keras.layers.RandomContrast(0.3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f814d901-0d46-42cc-b5c6-5eb4c71b5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Encoder():\n",
    "    inception_v3 = tf.keras.applications.InceptionV3(\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    inception_v3.trainable = False\n",
    "\n",
    "    output = inception_v3.output\n",
    "    output = tf.keras.layers.Reshape(\n",
    "        (-1, output.shape[-1]))(output)\n",
    "\n",
    "    cnn_model = tf.keras.models.Model(inception_v3.input, output)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c304f2bc-b74c-47d3-9693-a41b1d39638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization()\n",
    "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense = tf.keras.layers.Dense(embed_dim, activation=\"relu\")\n",
    "    \n",
    "\n",
    "    def call(self, x, training):\n",
    "        x = self.layer_norm_1(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        attn_output = self.attention(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x,\n",
    "            attention_mask=None,\n",
    "            training=training\n",
    "        )\n",
    "\n",
    "        x = self.layer_norm_2(x + attn_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8011e415-4af0-46fa-b4e6-225e063b918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, max_len):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = tf.keras.layers.Embedding(\n",
    "            vocab_size, embed_dim)\n",
    "        self.position_embeddings = tf.keras.layers.Embedding(\n",
    "            max_len, embed_dim, input_shape=(None, max_len))\n",
    "    \n",
    "\n",
    "    def call(self, input_ids):\n",
    "        length = tf.shape(input_ids)[-1]\n",
    "        position_ids = tf.range(start=0, limit=length, delta=1)\n",
    "        position_ids = tf.expand_dims(position_ids, axis=0)\n",
    "\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "\n",
    "        return token_embeddings + position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e527d99a-39d7-4133-9cd4-e0e8504b8e5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: /3580741947_cc64a83648.jpg : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Embeddings(tokenizer\u001b[38;5;241m.\u001b[39mvocabulary_size(), EMBEDDING_DIM, MAX_LENGTH)(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mC:\\miniconda\\envs\\py\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mC:\\miniconda\\envs\\py\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mC:\\miniconda\\envs\\py\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3016\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3018\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mC:\\miniconda\\envs\\py\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: /3580741947_cc64a83648.jpg : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "Embeddings(tokenizer.vocabulary_size(), EMBEDDING_DIM, MAX_LENGTH)(next(iter(train_dataset))[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709825b-9ae6-4194-b403-c5af1c3ad47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
